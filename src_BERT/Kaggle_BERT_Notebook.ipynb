{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-25T02:01:53.484494Z",
     "iopub.status.busy": "2025-11-25T02:01:53.484226Z",
     "iopub.status.idle": "2025-11-25T02:01:53.489207Z",
     "shell.execute_reply": "2025-11-25T02:01:53.488299Z",
     "shell.execute_reply.started": "2025-11-25T02:01:53.484475Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "'''\n",
    "Load all the packages we need for BERT training, data handling, and evaluation.\n",
    "'''\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from torch.optim import AdamW\n",
    "from transformers import BertTokenizer, BertModel, get_linear_schedule_with_warmup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T02:01:57.885905Z",
     "iopub.status.busy": "2025-11-25T02:01:57.885620Z",
     "iopub.status.idle": "2025-11-25T02:01:57.890291Z",
     "shell.execute_reply": "2025-11-25T02:01:57.889599Z",
     "shell.execute_reply.started": "2025-11-25T02:01:57.885883Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Configuration Settings\n",
    "\n",
    "'''\n",
    "Define all our hyperparameters: sequence length, batch sizes, number of epochs, and learning rate.\n",
    "'''\n",
    "\n",
    "MAX_LEN = 128             \n",
    "TRAIN_BATCH_SIZE = 16\n",
    "VALID_BATCH_SIZE = 8       \n",
    "EPOCHS = 3\n",
    "BERT_PATH = \"bert-base-uncased\"\n",
    "MODEL_PATH = \"bert_model.bin\"\n",
    "LEARNING_RATE = 3e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T02:02:10.654864Z",
     "iopub.status.busy": "2025-11-25T02:02:10.654571Z",
     "iopub.status.idle": "2025-11-25T02:02:10.662332Z",
     "shell.execute_reply": "2025-11-25T02:02:10.661599Z",
     "shell.execute_reply.started": "2025-11-25T02:02:10.654841Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Dataset and Model Classes\n",
    "\n",
    "'''\n",
    "BERTDataset handles tokenization and data loading. \n",
    "BERTBaseUncased is our BERT model with a classification head.\n",
    "'''\n",
    "\n",
    "class BERTDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, comment_text, target):\n",
    "        \n",
    "        self.comment_text = comment_text\n",
    "        self.target = target\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(BERT_PATH, do_lower_case=True)\n",
    "        self.max_len = MAX_LEN\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.comment_text)                                                   # Return how many samples there are\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        \n",
    "        comment_text = str(self.comment_text[item])                                     # Convert to string\n",
    "        comment_text = \" \".join(comment_text.split())                                   # Clean up whitespace\n",
    "        \n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            comment_text,\n",
    "            None,\n",
    "            add_special_tokens=True,                                                    # Add CLS and SEP tokens\n",
    "            max_length=self.max_len,                                                    # Pad or truncate to this length\n",
    "            padding='max_length',                                                       # Pad shorter sequences\n",
    "            truncation=True,                                                            # Cut off longer sequences\n",
    "            return_attention_mask=True,                                                 # Tell BERT which tokens are real vs padding\n",
    "            return_tensors='pt'                                                         # Return as PyTorch tensors\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'ids': inputs['input_ids'].flatten(),\n",
    "            'mask': inputs['attention_mask'].flatten(),\n",
    "            'targets': torch.tensor(self.target[item], dtype=torch.float)\n",
    "        }\n",
    "\n",
    "class BERTBaseUncased(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(BERTBaseUncased, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(BERT_PATH)\n",
    "        self.bert_drop = nn.Dropout(0.3)                                                # Dropout to prevent overfitting\n",
    "        self.out = nn.Linear(768, 1)                                                    # BERT outputs 768 dimensions with 1 output (toxic or not)\n",
    "    \n",
    "    def forward(self, ids, mask):\n",
    "        \n",
    "        outputs = self.bert(ids, attention_mask=mask)\n",
    "        \n",
    "        \n",
    "        pooled_output = outputs.pooler_output                                           # Use CLS token representation\n",
    "        \n",
    "        bo = self.bert_drop(pooled_output)\n",
    "        output = self.out(bo)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T02:02:14.763441Z",
     "iopub.status.busy": "2025-11-25T02:02:14.762714Z",
     "iopub.status.idle": "2025-11-25T02:02:14.775082Z",
     "shell.execute_reply": "2025-11-25T02:02:14.774194Z",
     "shell.execute_reply.started": "2025-11-25T02:02:14.763406Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Train and evaluate functions\n",
    "\n",
    "'''\n",
    "train_fn runs one epoch of training.\n",
    "eval_fn evaluates the model on validation data without updating weights.\n",
    "'''\n",
    "\n",
    "def train_fn(data_loader, model, optimizer, device, scheduler):\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for bi, d in enumerate(tqdm(data_loader, desc='Training')):\n",
    "        ids = d[\"ids\"].to(device)\n",
    "        mask = d[\"mask\"].to(device)\n",
    "        targets = d[\"targets\"].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()                                             # Zero out gradients from last batch\n",
    "        outputs = model(ids=ids, mask=mask)                               # Forward pass get predictions\n",
    "        \n",
    "        loss_fn = nn.BCEWithLogitsLoss()                                  # Calculate loss\n",
    "        loss = loss_fn(outputs, targets.view(-1, 1))\n",
    "        \n",
    "        loss.backward()                                                   # Calculate gradients\n",
    "        optimizer.step()                                                  # Update model weights\n",
    "        scheduler.step()                                                  # Update learning rate schedule\n",
    "        \n",
    "        total_loss += loss.item()                                         # Track total loss\n",
    "        \n",
    "        if bi % 100 == 0:                                                 # Double check progress\n",
    "            print(f\"Batch {bi}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    return total_loss / len(data_loader)                                  # Return average loss for the current epoch\n",
    "\n",
    "\n",
    "def eval_fn(data_loader, model, device):\n",
    "\n",
    "    model.eval()\n",
    "    fin_targets = []\n",
    "    fin_outputs = []\n",
    "\n",
    "    with torch.no_grad():                                                # Don't calculate gradients, just evaluating\n",
    "        for bi, d in enumerate(tqdm(data_loader, desc='Evaluating')):\n",
    "            ids = d[\"ids\"].to(device)\n",
    "            mask = d[\"mask\"].to(device)\n",
    "            targets = d[\"targets\"].to(device)\n",
    "            \n",
    "            outputs = model(ids=ids, mask=mask)                          # Get predictions\n",
    "            \n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())  # Collect all predictions and labels, convert to lists, move to CPU for calculations\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist()) # Apply signmoid to convert logits to probabilities (0 to 1)\n",
    "    \n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T02:02:32.337272Z",
     "iopub.status.busy": "2025-11-25T02:02:32.336991Z",
     "iopub.status.idle": "2025-11-25T02:02:32.341763Z",
     "shell.execute_reply": "2025-11-25T02:02:32.340953Z",
     "shell.execute_reply.started": "2025-11-25T02:02:32.337252Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Text preprocessing\n",
    "\n",
    "'''\n",
    "Removes HTML tags, URLs, and extra whitespace from comments.\n",
    "'''\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    \n",
    "    text = re.sub(r'<.*?>', '', text)          # Remove HTML tags\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text) # Remove URLs\n",
    "    text = ' '.join(text.split())              # Remove extra whitespace\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T02:02:57.173087Z",
     "iopub.status.busy": "2025-11-25T02:02:57.172808Z",
     "iopub.status.idle": "2025-11-25T02:03:50.624768Z",
     "shell.execute_reply": "2025-11-25T02:03:50.623910Z",
     "shell.execute_reply.started": "2025-11-25T02:02:57.173066Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Training model\n",
    "\n",
    "'''\n",
    "Loads data, preprocesses it, trains BERT for 3 epochs, and saves the best model based on accuracy.\n",
    "'''\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"\\nUsing device: {device}\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    \n",
    "    df = pd.read_csv(\"/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip\", usecols=[\"comment_text\", \"toxic\"]) # Load data from Kaggle\n",
    "    \n",
    "    print(f\"Before cleaning: {len(df)}\")\n",
    "    \n",
    "    # Preprocessing\n",
    "    df = df.dropna(subset=['comment_text', 'toxic'])                 # Remove rows with missing data\n",
    "    df = df[df['comment_text'].str.strip() != '']                    # Remove rows that are empty/whitespace\n",
    "    df = df[df['comment_text'].str.len() < 5000]                     # Remove rows with super long comments\n",
    "    df['comment_text'] = df['comment_text'].apply(clean_text)        # Apply text cleaning to each row\n",
    "    df = df[df['comment_text'].str.strip() != '']                    # Remove rows that became empty after cleaning\n",
    "    \n",
    "    print(f\"After cleaning: {len(df)}\")\n",
    "    \n",
    "    df = df.sample(n=75000, random_state=42)                         # Train from 75k comments instead of the full 160k\n",
    "    print(f\"Using {len(df)} samples\")\n",
    "    \n",
    "    \n",
    "    df_train, df_valid = model_selection.train_test_split(           # Train/validation split, 90% train, 10% validation\n",
    "        df,\n",
    "        test_size=0.1,\n",
    "        random_state=42,\n",
    "        stratify=df.toxic.values\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nTraining samples: {len(df_train)}\")\n",
    "    print(f\"Validation samples: {len(df_valid)}\")\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = BERTDataset(\n",
    "        comment_text=df_train.comment_text.values,\n",
    "        target=df_train.toxic.values\n",
    "    )\n",
    "    \n",
    "    valid_dataset = BERTDataset(\n",
    "        comment_text=df_valid.comment_text.values,\n",
    "        target=df_valid.toxic.values\n",
    "    )\n",
    "\n",
    "    # Create data loaders\n",
    "    train_data_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=TRAIN_BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=0                                             # Set to 0 for Kaggle compatibility\n",
    "    )\n",
    "    \n",
    "    valid_data_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=VALID_BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=0\n",
    "    )\n",
    "    \n",
    "    \n",
    "    model = BERTBaseUncased()                                    # Create model\n",
    "    model.to(device)\n",
    "    \n",
    "    print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    \n",
    "    param_optimizer = list(model.named_parameters())             # Optimizer setup\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_parameters = [\n",
    "        {\"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\"weight_decay\": 0.001,},\n",
    "        {\"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\"weight_decay\": 0.0,},\n",
    "    ]\n",
    "    \n",
    "    num_train_steps = int(len(df_train) / TRAIN_BATCH_SIZE * EPOCHS)  # Calculate the total training steps for the learning rate scheduler\n",
    "    \n",
    "    optimizer = AdamW(optimizer_parameters, lr=LEARNING_RATE)         # Using AdamW as it works well with transformers\n",
    "    \n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=num_train_steps\n",
    "    )\n",
    "    \n",
    "    # Training loop\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n",
    "        \n",
    "        \n",
    "        train_loss = train_fn(train_data_loader, model, optimizer, device, scheduler) # Train for one epoch\n",
    "        print(f\"Average training loss: {train_loss:.4f}\")\n",
    "        \n",
    "        \n",
    "        outputs, targets = eval_fn(valid_data_loader, model, device)                  # Evaluate on validation set\n",
    "        \n",
    "        outputs = np.array(outputs) >= 0.5                                            # Convert probabilities to binary predictions, anything >= .5 is toxic\n",
    "\n",
    "        # Calculate all of the needed metrics\n",
    "        accuracy = metrics.accuracy_score(targets, outputs)\n",
    "        precision = metrics.precision_score(targets, outputs)\n",
    "        recall = metrics.recall_score(targets, outputs)\n",
    "        f1 = metrics.f1_score(targets, outputs)\n",
    "        auc = metrics.roc_auc_score(targets, outputs)\n",
    "        \n",
    "        print(f\"\\nValidation Metrics:\")\n",
    "        print(f\"  Accuracy:  {accuracy*100:.2f}%\")\n",
    "        print(f\"  Precision: {precision*100:.2f}%\")\n",
    "        print(f\"  Recall:    {recall*100:.2f}%\")\n",
    "        print(f\"  F1-Score:  {f1:.4f}\")\n",
    "        print(f\"  AUC:       {auc:.4f}\")\n",
    "\n",
    "        # Save the best model\n",
    "        if accuracy > best_accuracy:\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'config': {\n",
    "                    'max_len': MAX_LEN,\n",
    "                    'bert_path': BERT_PATH\n",
    "                },\n",
    "                'metrics': {\n",
    "                    'accuracy': accuracy,\n",
    "                    'precision': precision,\n",
    "                    'recall': recall,\n",
    "                    'f1_score': f1,\n",
    "                    'auc': auc\n",
    "                }\n",
    "            }, MODEL_PATH)\n",
    "            print(f\"Best model (Accuracy: {accuracy*100:.2f}%)\")\n",
    "            best_accuracy = accuracy\n",
    "    \n",
    "    print(f\"Best Accuracy: {best_accuracy*100:.2f}%\")\n",
    "    print(f\"Model saved to: {MODEL_PATH}\")\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T06:07:35.963277Z",
     "iopub.status.busy": "2025-11-22T06:07:35.963134Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 44219,
     "isSourceIdPinned": false,
     "sourceId": 8076,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
